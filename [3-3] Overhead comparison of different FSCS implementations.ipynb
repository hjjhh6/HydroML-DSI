{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import psutil\n",
    "from memory_profiler import memory_usage\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sklearn and sklearnex\n",
    "from sklearn.cluster import KMeans as SKLearnKMeans\n",
    "from sklearnex import patch_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7940ee6",
   "metadata": {},
   "source": [
    "Fitting analysis of FSCS sampling method implemented in matlab-kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read completed experiment results (including raw_n, feat_num, level, comb_idx, elapsed_time, peak_mem_used)\n",
    "df = pd.read_csv(\"FSCS_overhead_with_rawsize.csv\")\n",
    "\n",
    "# Keep only valid data\n",
    "df = df[(df[\"elapsed_time\"] > 0) & (df[\"peak_mem_used\"] > 0)]\n",
    "\n",
    "# Define independent and dependent variables\n",
    "n = df[\"raw_n\"].values\n",
    "k = df[\"level\"].values\n",
    "d = df[\"feat_num\"].values\n",
    "t = df[\"elapsed_time\"].values  # Running time (seconds)\n",
    "m = df[\"peak_mem_used\"].values  # Peak memory (MB)\n",
    "\n",
    "\n",
    "# Define memory model (power law form)\n",
    "def mem_model(X, C, beta, a, b, c):\n",
    "    n, k, d = X\n",
    "    return C + beta * (n**a) * (k**b) * (d**c)\n",
    "\n",
    "\n",
    "# Initial guess values\n",
    "p0_mem = [10000, 1e-8, 1.0, 1.0, 0.0]\n",
    "\n",
    "# Fit the model\n",
    "popt_mem, pcov_mem = curve_fit(mem_model, (n, k, d), m, p0=p0_mem, maxfev=50000)\n",
    "C_m, beta_m, a_m, b_m, c_m = popt_mem\n",
    "\n",
    "# Calculate fitted values and R²\n",
    "m_pred = mem_model((n, k, d), *popt_mem)\n",
    "r2_mem = r2_score(m, m_pred)\n",
    "\n",
    "# Print model parameters and R²\n",
    "print(\"===== Peak Memory Model (Power Law) =====\")\n",
    "print(f\"C      = {C_m:.2f}\")\n",
    "print(f\"β      = {beta_m:.4e}\")\n",
    "print(f\"a (n^a) = {a_m:.4f}\")\n",
    "print(f\"b (k^b) = {b_m:.4f}\")\n",
    "print(f\"c (d^c) = {c_m:.4f}\")\n",
    "print(f\"R²     = {r2_mem:.4f}\")\n",
    "\n",
    "\n",
    "# Define running time model (power law form)\n",
    "def time_model(X, C, beta, a, b, c):\n",
    "    n, k, d = X\n",
    "    return C + beta * (n**a) * (k**b) * (d**c)\n",
    "\n",
    "\n",
    "# Initial guess values\n",
    "p0_time = [100, 1e-12, 1.0, 1.0, 0.0]\n",
    "\n",
    "# Fit the model\n",
    "popt_time, pcov_time = curve_fit(time_model, (n, k, d), t, p0=p0_time, maxfev=50000)\n",
    "C_t, beta_t, a_t, b_t, c_t = popt_time\n",
    "\n",
    "# Calculate fitted values and R²\n",
    "t_pred = time_model((n, k, d), *popt_time)\n",
    "r2_time = r2_score(t, t_pred)\n",
    "\n",
    "# Print model parameters and R²\n",
    "print(\"===== Running Time Model (Power Law) =====\")\n",
    "print(f\"C      = {C_t:.2f}\")\n",
    "print(f\"β      = {beta_t:.4e}\")\n",
    "print(f\"a (n^a) = {a_t:.4f}\")\n",
    "print(f\"b (k^b) = {b_t:.4f}\")\n",
    "print(f\"c (d^c) = {c_t:.4f}\")\n",
    "print(f\"R²     = {r2_time:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7549a34",
   "metadata": {},
   "source": [
    "Comparative analysis of MATLAB, scikit-learn, and scikit-learn-ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "# Read CSV\n",
    "grd = pd.read_csv(\"sampleddata/class_df.csv\")\n",
    "grd_data = grd.iloc[:, 1:-1].values\n",
    "grd_scaled = StandardScaler().fit_transform(grd_data).astype(np.float32)\n",
    "\n",
    "# Test parameters\n",
    "n_repeats = 5\n",
    "# Cell [2]: Test parameters\n",
    "n_repeats = 5\n",
    "raw_ns = [50000, 80000, 100000]  # List of raw sample sizes\n",
    "cluster_counts = [5000, 10000, 20000, 50000, 80000]\n",
    "max_iter = 100\n",
    "random_state = 2025\n",
    "\n",
    "\n",
    "# Randomly sample n_samples from the full dataset\n",
    "def sample_data(data, n_samples, seed=None):\n",
    "    if n_samples >= data.shape[0]:\n",
    "        return data\n",
    "    idx = shuffle(np.arange(data.shape[0]), random_state=seed)[:n_samples]\n",
    "    return data[idx, :]\n",
    "\n",
    "\n",
    "X = grd_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db776126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU memory monitor (for Jupyter environment)\n",
    "\n",
    "\n",
    "class JupyterMemoryMonitor:\n",
    "    def __init__(self):\n",
    "        self.process = psutil.Process(os.getpid())\n",
    "        self.peak_memory = 0\n",
    "        self._is_running = False\n",
    "        self._monitor_thread = None\n",
    "\n",
    "    def start(self):\n",
    "        self.peak_memory = 0\n",
    "        self._is_running = True\n",
    "        self._monitor_thread = threading.Thread(target=self._monitor)\n",
    "        self._monitor_thread.daemon = True\n",
    "        self._monitor_thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        self._is_running = False\n",
    "        if self._monitor_thread:\n",
    "            self._monitor_thread.join()\n",
    "        return self.peak_memory / 1024**2  # Unit: MB\n",
    "\n",
    "    def _monitor(self):\n",
    "        while self._is_running:\n",
    "            current = self.process.memory_info().rss\n",
    "            if current > self.peak_memory:\n",
    "                self.peak_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement function\n",
    "\n",
    "\n",
    "def measure_kmeans(cls, data, **kwargs):\n",
    "    \"\"\"\n",
    "    General measurement function, only for SKLearnKMeans and SKLearnexKMeans:\n",
    "    - Use memory_usage to monitor the peak CPU memory inside the function\n",
    "    - Use JupyterMemoryMonitor to monitor the peak CPU memory during the whole process\n",
    "    Returns: (elapsed_time_s, peak_cpu_func_mem_MB, peak_cpu_jupyter_mem_MB)\n",
    "    \"\"\"\n",
    "    cpu_monitor = JupyterMemoryMonitor()\n",
    "    cpu_monitor.start()\n",
    "\n",
    "    def run_kmeans_cpu():\n",
    "        km = cls(\n",
    "            n_clusters=kwargs.get(\"n_clusters\"),\n",
    "            max_iter=kwargs.get(\"max_iter\", 100),\n",
    "            n_init=kwargs.get(\"n_init\", 1),\n",
    "            algorithm=kwargs.get(\"algorithm\", \"lloyd\"),\n",
    "            random_state=kwargs.get(\"random_state\", None),\n",
    "        )\n",
    "        km.fit(data)\n",
    "\n",
    "    # Monitor the peak CPU memory inside the function\n",
    "    mem_usage = memory_usage(proc=run_kmeans_cpu, interval=0.01)\n",
    "\n",
    "    # Measure running time\n",
    "    t0 = time.time()\n",
    "    run_kmeans_cpu()\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    cpu_peak_jup = cpu_monitor.stop()\n",
    "\n",
    "    return (\n",
    "        round(elapsed, 2),\n",
    "        round(max(mem_usage), 2),\n",
    "        round(cpu_peak_jup, 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native scikit-learn test (modified)\n",
    "results_native = []\n",
    "for raw_n in raw_ns:\n",
    "    # For each raw_n, sample once\n",
    "    X_sampled = sample_data(X, raw_n, random_state)\n",
    "    for k in cluster_counts:\n",
    "        if k > raw_n:\n",
    "            continue\n",
    "        for r in range(n_repeats):\n",
    "            t, m_func, m_jup = measure_kmeans(\n",
    "                SKLearnKMeans,\n",
    "                X_sampled,\n",
    "                n_clusters=k,\n",
    "                max_iter=max_iter,\n",
    "                n_init=1,\n",
    "                algorithm=\"lloyd\",\n",
    "                random_state=random_state + r,\n",
    "            )\n",
    "            results_native.append(\n",
    "                {\n",
    "                    \"raw_n\": raw_n,\n",
    "                    \"k\": k,\n",
    "                    \"repeat\": r,\n",
    "                    \"sklearn_time_s\": t,\n",
    "                    \"sklearn_cpu_func_mem_MB\": m_func,\n",
    "                    \"sklearn_cpu_jupyter_mem_MB\": m_jup,\n",
    "                }\n",
    "            )\n",
    "\n",
    "df_native = pd.DataFrame(results_native).set_index([\"raw_n\", \"k\", \"repeat\"])\n",
    "display(df_native)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673920d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearnex accelerated test (modified)\n",
    "patch_sklearn()\n",
    "from sklearn.cluster import KMeans as SKLearnexKMeans\n",
    "\n",
    "results_ex = []\n",
    "for raw_n in raw_ns:\n",
    "    X_sampled = sample_data(X, raw_n, random_state)\n",
    "    for k in cluster_counts:\n",
    "        if k > raw_n:\n",
    "            continue\n",
    "        for r in range(n_repeats):\n",
    "            t, m_func, m_jup = measure_kmeans(\n",
    "                SKLearnexKMeans,\n",
    "                X_sampled,\n",
    "                n_clusters=k,\n",
    "                max_iter=max_iter,\n",
    "                n_init=1,\n",
    "                algorithm=\"lloyd\",\n",
    "                random_state=random_state + r,\n",
    "            )\n",
    "            results_ex.append(\n",
    "                {\n",
    "                    \"raw_n\": raw_n,\n",
    "                    \"k\": k,\n",
    "                    \"repeat\": r,\n",
    "                    \"sklearnex_time_s\": t,\n",
    "                    \"sklearnex_cpu_func_mem_MB\": m_func,\n",
    "                    \"sklearnex_cpu_jupyter_mem_MB\": m_jup,\n",
    "                }\n",
    "            )\n",
    "\n",
    "df_ex = pd.DataFrame(results_ex).set_index([\"raw_n\", \"k\", \"repeat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the code for reading and merging MATLAB results to ensure all combinations of raw_ns and cluster_counts are processed\n",
    "has_matlab = False\n",
    "try:\n",
    "    # Read MATLAB data\n",
    "    matlab_df = pd.read_csv(\"FSCS_overhead_with_rawsize.csv\")\n",
    "\n",
    "    # Filter valid data\n",
    "    matlab_df = matlab_df[\n",
    "        (matlab_df[\"elapsed_time\"] > 0) & (matlab_df[\"peak_mem_used\"] > 0)\n",
    "    ]\n",
    "\n",
    "    # Initialize result list\n",
    "    matlab_results = []\n",
    "\n",
    "    # Iterate over all combinations of raw_ns and cluster_counts\n",
    "    for raw_n in raw_ns:\n",
    "        for k in cluster_counts:\n",
    "            if k > raw_n:\n",
    "                continue\n",
    "            # Filter data for current raw_n and k\n",
    "            subset = matlab_df[\n",
    "                (matlab_df[\"raw_n\"] == raw_n) & (matlab_df[\"level\"] == k)\n",
    "            ]\n",
    "\n",
    "            # If data is empty, skip current combination\n",
    "            if subset.empty:\n",
    "                avg_time, avg_mem = np.nan, np.nan\n",
    "            else:\n",
    "                avg_time = subset[\"elapsed_time\"].mean()\n",
    "                avg_mem = subset[\"peak_mem_used\"].mean()\n",
    "\n",
    "            # Repeat n_repeats times for consistency\n",
    "            for r in range(n_repeats):\n",
    "                matlab_results.append(\n",
    "                    {\n",
    "                        \"raw_n\": raw_n,\n",
    "                        \"k\": k,\n",
    "                        \"repeat\": r,\n",
    "                        \"matlab_time_s\": avg_time,\n",
    "                        \"matlab_cpu_func_mem_MB\": avg_mem,\n",
    "                        \"matlab_cpu_jupyter_mem_MB\": avg_mem,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_matlab = pd.DataFrame(matlab_results).set_index([\"raw_n\", \"k\", \"repeat\"])\n",
    "    has_matlab = True\n",
    "    # Reset index to convert raw_n, k, repeat to regular columns\n",
    "    df_matlab_reset = df_matlab.reset_index()\n",
    "    display(df_matlab)\n",
    "\n",
    "except Exception as e:\n",
    "    # Catch exceptions and print error message\n",
    "    print(\"Failed to read MATLAB results:\", e)\n",
    "    has_matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da414f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all results & calculate mean and standard deviation\n",
    "\n",
    "# Ensure MultiIndex for df_comb\n",
    "df_comb = pd.concat([df_native, df_ex, df_matlab_reset], axis=1)\n",
    "df_comb.index = pd.MultiIndex.from_frame(df_comb.reset_index()[[\"raw_n\", \"k\"]])\n",
    "df_comb.to_csv(\"output.csv\", index=False)\n",
    "\n",
    "# Group by MultiIndex levels and calculate mean\n",
    "df_mean = df_comb.groupby(level=[\"raw_n\", \"k\"]).mean()\n",
    "\n",
    "\n",
    "# Filter columns containing only time_s and memory related columns\n",
    "time_memory_columns = [\n",
    "    col for col in df_mean.columns if \"time_s\" in col or \"mem_MB\" in col\n",
    "]\n",
    "df_mean_filtered = df_mean[time_memory_columns]\n",
    "df.to_csv(\"tool compare results comparison.csv\", index=False)\n",
    "\n",
    "# Display results\n",
    "print(\"===== Mean =====\")\n",
    "display(df_mean_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "t = df[\"elapsed_time\"].values\n",
    "\n",
    "# Prepare DataFrames\n",
    "df_plot = df_mean_filtered.reset_index()\n",
    "\n",
    "mem_cols = {\n",
    "    \"sklearn_cpu_jupyter_mem_MB\": \"scikit-learn\",\n",
    "    \"sklearnex_cpu_jupyter_mem_MB\": \"scikit-learnex\",\n",
    "}\n",
    "if has_matlab:\n",
    "    mem_cols[\"matlab_cpu_jupyter_mem_MB\"] = \"MATLAB\"\n",
    "df_mem = df_plot[[\"raw_n\", \"k\"] + list(mem_cols.keys())].rename(columns=mem_cols)\n",
    "\n",
    "time_cols = {\"sklearn_time_s\": \"scikit-learn\", \"sklearnex_time_s\": \"scikit-learnex\"}\n",
    "if has_matlab:\n",
    "    time_cols[\"matlab_time_s\"] = \"MATLAB\"\n",
    "df_time = df_plot[[\"raw_n\", \"k\"] + list(time_cols.keys())].rename(columns=time_cols)\n",
    "\n",
    "# Plot settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "\n",
    "# Create 4×2 grid\n",
    "fig, axes = plt.subplots(4, 2, figsize=(18, 24))\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "\n",
    "# subplot labels (a)-(h)\n",
    "labels = [\"(a)\", \"(b)\", \"(c)\", \"(d)\", \"(e)\", \"(f)\", \"(g)\", \"(h)\"]\n",
    "\n",
    "# 1st row: fit scatter plots with R²\n",
    "axes[0, 0].scatter(m, m_pred, alpha=0.4)\n",
    "lims = [min(m.min(), m_pred.min()), max(m.max(), m_pred.max())]\n",
    "axes[0, 0].plot(lims, lims, \"r--\")\n",
    "axes[0, 0].set_xlabel(\"Observed Peak Memory (MB)\")\n",
    "axes[0, 0].set_ylabel(\"Predicted Peak Memory (MB)\")\n",
    "axes[0, 0].grid(True)\n",
    "axes[0, 0].set_title(\n",
    "    f\"(a) Memory Fit\\n(Exponential Saturation), R²={r2_mem:.3f}\", pad=20\n",
    ")\n",
    "\n",
    "axes[0, 1].scatter(t, t_pred, alpha=0.4)\n",
    "lims = [min(t.min(), t_pred.min()), max(t.max(), t_pred.max())]\n",
    "axes[0, 1].plot(lims, lims, \"r--\")\n",
    "axes[0, 1].set_xlabel(\"Observed Time (s)\")\n",
    "axes[0, 1].set_ylabel(\"Predicted Time (s)\")\n",
    "axes[0, 1].grid(True)\n",
    "axes[0, 1].set_title(\n",
    "    f\"(b) Time Fit\\n(Exponential Saturation), R²={r2_time:.3f}\", pad=20\n",
    ")\n",
    "\n",
    "\n",
    "# Helper for annotation\n",
    "def annotate_multiples(ax, df_sub, baseline_col):\n",
    "    methods = [c for c in df_sub.columns if c not in (\"raw_n\", \"k\")]\n",
    "    n_methods = len(methods)\n",
    "    ks = df_sub[\"k\"].values\n",
    "    for i, k_val in enumerate(ks):\n",
    "        baseline = float(df_sub.loc[df_sub[\"k\"] == k_val, baseline_col])\n",
    "        for j, method in enumerate(methods):\n",
    "            height = float(df_sub.loc[df_sub[\"k\"] == k_val, method])\n",
    "            multiple = height / baseline if baseline else np.nan\n",
    "            x_pos = i + (j - (n_methods - 1) / 2) * 0.25\n",
    "            ax.text(\n",
    "                x_pos,\n",
    "                height * 1.01,\n",
    "                f\"{multiple:.1f}×\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=15,\n",
    "            )\n",
    "\n",
    "\n",
    "# 2nd–4th rows: bar plots per raw_n\n",
    "for idx, raw_n in enumerate([50000, 80000, 100000], start=1):\n",
    "    mem_sub = df_mem[df_mem[\"raw_n\"] == raw_n].copy()\n",
    "    time_sub = df_time[df_time[\"raw_n\"] == raw_n].copy()\n",
    "    # predict missing MATLAB\n",
    "    if raw_n == 100000 and has_matlab:\n",
    "        pred_m = mem_model((100000, 80000, d.mean()), *popt_mem)\n",
    "        pred_t = time_model((100000, 80000, d.mean()), *popt_time)\n",
    "        mem_sub.loc[mem_sub.k == 80000, \"MATLAB\"] = pred_m\n",
    "        time_sub.loc[time_sub.k == 80000, \"MATLAB\"] = pred_t\n",
    "\n",
    "    mem_melt = mem_sub.melt(\n",
    "        id_vars=\"k\",\n",
    "        value_vars=list(mem_cols.values()),\n",
    "        var_name=\"Method\",\n",
    "        value_name=\"Memory\",\n",
    "    )\n",
    "    time_melt = time_sub.melt(\n",
    "        id_vars=\"k\",\n",
    "        value_vars=list(time_cols.values()),\n",
    "        var_name=\"Method\",\n",
    "        value_name=\"Time\",\n",
    "    )\n",
    "\n",
    "    # Memory bar\n",
    "    axm = axes[idx, 0]\n",
    "    sns.barplot(data=mem_melt, x=\"k\", y=\"Memory\", hue=\"Method\", ax=axm)\n",
    "    axm.set_title(\n",
    "        f\"{labels[2*idx]} Sampling Dataset Level = {raw_n}\\nAverage Peak CPU Memory for KMeans\",\n",
    "        wrap=True,\n",
    "        pad=20,\n",
    "    )\n",
    "    axm.set_xlabel(\"Sampling Dataset Level\")\n",
    "    axm.set_ylabel(\"Average Peak CPU Memory (MB)\")\n",
    "    axm.grid(True, which=\"major\", linestyle=\"-\", linewidth=1)\n",
    "    axm.minorticks_on()\n",
    "    axm.grid(True, which=\"minor\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "    annotate_multiples(axm, mem_sub, baseline_col=\"scikit-learn\")\n",
    "\n",
    "    # Time bar\n",
    "    axt = axes[idx, 1]\n",
    "    sns.barplot(data=time_melt, x=\"k\", y=\"Time\", hue=\"Method\", ax=axt)\n",
    "    axt.set_title(\n",
    "        f\"{labels[2*idx+1]} Sampling Dataset Level = {raw_n}\\nAverage Running Time for KMeans\",\n",
    "        wrap=True,\n",
    "        pad=20,\n",
    "    )\n",
    "    axt.set_xlabel(\"Sampling Dataset Level\")\n",
    "    axt.set_ylabel(\"Average Time (s)\")\n",
    "    axt.grid(True, which=\"major\", linestyle=\"-\", linewidth=1)\n",
    "    axt.minorticks_on()\n",
    "    axt.grid(True, which=\"minor\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "    annotate_multiples(axm, mem_sub, baseline_col=\"scikit-learn\")\n",
    "    annotate_multiples(axt, time_sub, baseline_col=\"scikit-learn\")\n",
    "\n",
    "    # Hatch predicted MATLAB\n",
    "    if raw_n == 100000 and has_matlab:\n",
    "        for patch in axm.patches:\n",
    "            if np.isclose(patch.get_height(), pred_m, rtol=1e-3):\n",
    "                patch.set_hatch(\"//\")\n",
    "                patch.set_edgecolor(\"black\")\n",
    "        for patch in axt.patches:\n",
    "            if np.isclose(patch.get_height(), pred_t, rtol=1e-3):\n",
    "                patch.set_hatch(\"//\")\n",
    "                patch.set_edgecolor(\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
