{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e42af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_rel, mannwhitneyu\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cliffs_delta import cliffs_delta\n",
    "\n",
    "\n",
    "# 读取结果\n",
    "lgb_results_df = pd.read_csv(\"lgbKsatresults_all.csv\")\n",
    "rf_results_df = pd.read_csv(\"rfKsatresults_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sampling method, dataset level, and set_id\n",
    "lgb_results_with_methods = lgb_results_df.copy()\n",
    "lgb_results_with_methods[\"sampling_method\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[0]\n",
    ")\n",
    "lgb_results_with_methods[\"dataset_level\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-3]\n",
    ")\n",
    "lgb_results_with_methods[\"set_id\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1]\n",
    ")\n",
    "lgb_results_with_methods[\"model\"] = \"LGB\"\n",
    "\n",
    "rf_results_with_methods = rf_results_df.copy()\n",
    "rf_results_with_methods[\"sampling_method\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[0]\n",
    ")\n",
    "rf_results_with_methods[\"dataset_level\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-3]\n",
    ")\n",
    "rf_results_with_methods[\"set_id\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1]\n",
    ")\n",
    "rf_results_with_methods[\"model\"] = \"RF\"\n",
    "\n",
    "# Combine\n",
    "combined_results_with_methods = pd.concat(\n",
    "    [rf_results_with_methods, lgb_results_with_methods], ignore_index=True\n",
    ")\n",
    "combined_results_with_methods = combined_results_with_methods[\n",
    "    [\"sampling_method\", \"dataset_level\", \"set_id\", \"r2\", \"rmsle\", \"model\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significance and effect size analysis\n",
    "metrics = [\"r2\", \"rmsle\"]\n",
    "models = [\"RF\", \"LGB\"]\n",
    "sampling_methods = combined_results_with_methods[\"sampling_method\"].unique()\n",
    "sampling_methods = [m for m in sampling_methods if m != \"FSCS\"]\n",
    "dataset_levels = combined_results_with_methods[\"dataset_level\"].unique()\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ca87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FSCS vs other sampling methods within the same model\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        for dataset_level in dataset_levels:\n",
    "            for idx, method in enumerate(sampling_methods):\n",
    "                fscs = combined_results_with_methods[\n",
    "                    (combined_results_with_methods[\"sampling_method\"] == \"FSCS\")\n",
    "                    & (combined_results_with_methods[\"model\"] == model)\n",
    "                    & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "                ]\n",
    "                other = combined_results_with_methods[\n",
    "                    (combined_results_with_methods[\"sampling_method\"] == method)\n",
    "                    & (combined_results_with_methods[\"model\"] == model)\n",
    "                    & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "                ]\n",
    "                merged = pd.merge(\n",
    "                    fscs,\n",
    "                    other,\n",
    "                    on=[\"dataset_level\", \"set_id\"],\n",
    "                    suffixes=(\"_fscs\", \"_other\"),\n",
    "                )\n",
    "                if len(merged) == 0:\n",
    "                    continue\n",
    "                diff = merged[f\"{metric}_fscs\"] - merged[f\"{metric}_other\"]\n",
    "                # Mann-Whitney U test and effect size r\n",
    "                try:\n",
    "                    stat, p_u = mannwhitneyu(\n",
    "                        merged[f\"{metric}_other\"],\n",
    "                        merged[f\"{metric}_fscs\"],\n",
    "                        alternative=\"two-sided\",\n",
    "                    )\n",
    "                    n1, n2 = len(merged[f\"{metric}_fscs\"]), len(\n",
    "                        merged[f\"{metric}_other\"]\n",
    "                    )\n",
    "                    r_rb = 1 - 2 * stat / (n1 * n2) if n1 > 0 and n2 > 0 else np.nan\n",
    "                except Exception:\n",
    "                    stat = np.nan\n",
    "                    p_u = np.nan\n",
    "                    r_rb = np.nan\n",
    "                # Cliff's delta\n",
    "                try:\n",
    "                    from cliffs_delta import cliffs_delta\n",
    "\n",
    "                    cd, _ = cliffs_delta(\n",
    "                        merged[f\"{metric}_fscs\"], merged[f\"{metric}_other\"]\n",
    "                    )\n",
    "                except Exception:\n",
    "                    cd = np.nan\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"model\": model,\n",
    "                        \"metric\": metric,\n",
    "                        \"dataset_level\": dataset_level,\n",
    "                        \"method_vs\": method,\n",
    "                        \"mw_U\": stat,\n",
    "                        \"mw_p\": p_u,\n",
    "                        \"r_rb\": r_rb,\n",
    "                        \"CD\": cd,\n",
    "                    }\n",
    "                )\n",
    "# 2. RF+FSCS vs LGB+Other Sampling Methods\n",
    "for metric in metrics:\n",
    "    for dataset_level in dataset_levels:\n",
    "        for method in sampling_methods:\n",
    "            rf_fscs = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == \"FSCS\")\n",
    "                & (combined_results_with_methods[\"model\"] == \"RF\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            lgb_other = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == method)\n",
    "                & (combined_results_with_methods[\"model\"] == \"LGB\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            merged = pd.merge(\n",
    "                rf_fscs,\n",
    "                lgb_other,\n",
    "                on=[\"dataset_level\", \"set_id\"],\n",
    "                suffixes=(\"_rf_fscs\", \"_lgb_other\"),\n",
    "            )\n",
    "            if len(merged) == 0:\n",
    "                continue\n",
    "            diff = merged[f\"{metric}_rf_fscs\"] - merged[f\"{metric}_lgb_other\"]\n",
    "            try:\n",
    "                stat, p_u = mannwhitneyu(\n",
    "                    merged[f\"{metric}_lgb_other\"],\n",
    "                    merged[f\"{metric}_rf_fscs\"],\n",
    "                    alternative=\"two-sided\",\n",
    "                )\n",
    "                n1, n2 = len(merged[f\"{metric}_rf_fscs\"]), len(\n",
    "                    merged[f\"{metric}_lgb_other\"]\n",
    "                )\n",
    "                r_rb = 1 - ((2 * stat) / (n1 * n2)) if n1 > 0 and n2 > 0 else np.nan\n",
    "            except Exception:\n",
    "                stat = np.nan\n",
    "                p_u = np.nan\n",
    "                r_rb = np.nan\n",
    "            try:\n",
    "                from cliffs_delta import cliffs_delta\n",
    "\n",
    "                cd, _ = cliffs_delta(\n",
    "                    merged[f\"{metric}_rf_fscs\"], merged[f\"{metric}_lgb_other\"]\n",
    "                )\n",
    "            except Exception:\n",
    "                cd = np.nan\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model\": \"RF_FSCS_vs_LGB_other\",\n",
    "                    \"metric\": metric,\n",
    "                    \"dataset_level\": dataset_level,\n",
    "                    \"method_vs\": method,\n",
    "                    \"mw_U\": stat,\n",
    "                    \"mw_p\": p_u,\n",
    "                    \"r_rb\": r_rb,\n",
    "                    \"CD\": cd,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# 3. LGB+FSCS vs RF+Other Sampling Methods\n",
    "for metric in metrics:\n",
    "    for dataset_level in dataset_levels:\n",
    "        for method in sampling_methods:\n",
    "            lgb_fscs = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == \"FSCS\")\n",
    "                & (combined_results_with_methods[\"model\"] == \"LGB\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            rf_other = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == method)\n",
    "                & (combined_results_with_methods[\"model\"] == \"RF\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            merged = pd.merge(\n",
    "                lgb_fscs,\n",
    "                rf_other,\n",
    "                on=[\"dataset_level\", \"set_id\"],\n",
    "                suffixes=(\"_lgb_fscs\", \"_rf_other\"),\n",
    "            )\n",
    "            if len(merged) == 0:\n",
    "                continue\n",
    "            diff = merged[f\"{metric}_lgb_fscs\"] - merged[f\"{metric}_rf_other\"]\n",
    "            try:\n",
    "                stat, p_u = mannwhitneyu(\n",
    "                    merged[f\"{metric}_rf_other\"],\n",
    "                    merged[f\"{metric}_lgb_fscs\"],\n",
    "                    alternative=\"two-sided\",\n",
    "                )\n",
    "                n1, n2 = len(merged[f\"{metric}_lgb_fscs\"]), len(\n",
    "                    merged[f\"{metric}_rf_other\"]\n",
    "                )\n",
    "                r_rb = 1 - 2 * stat / (n1 * n2) if n1 > 0 and n2 > 0 else np.nan\n",
    "            except Exception:\n",
    "                stat = np.nan\n",
    "                p_u = np.nan\n",
    "                r_rb = np.nan\n",
    "            try:\n",
    "                from cliffs_delta import cliffs_delta\n",
    "\n",
    "                cd, _ = cliffs_delta(\n",
    "                    merged[f\"{metric}_lgb_fscs\"], merged[f\"{metric}_rf_other\"]\n",
    "                )\n",
    "            except Exception:\n",
    "                cd = np.nan\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model\": \"LGB_FSCS_vs_RF_other\",\n",
    "                    \"metric\": metric,\n",
    "                    \"dataset_level\": dataset_level,\n",
    "                    \"method_vs\": method,\n",
    "                    \"mw_U\": stat,\n",
    "                    \"mw_p\": p_u,\n",
    "                    \"r_rb\": r_rb,\n",
    "                    \"CD\": cd,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Summary table\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 22})\n",
    "\n",
    "ur_thresholds = [0.1, 0.3, 0.5]\n",
    "cd_thresholds = [0.147, 0.33, 0.474]\n",
    "sampling_methods = [\"BalancedSampling\", \"clhs\", \"SRS\"]\n",
    "sampling_labels = [\"Balanced\\nSampling\", \"CLHS\", \"SRS\"]\n",
    "\n",
    "effect_legend = [\n",
    "    Line2D(\n",
    "        [0], [0], marker=\"x\", color=\"blue\", lw=0, markersize=14, label=\"Small effect\"\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"orange\",\n",
    "        markerfacecolor=\"none\",\n",
    "        lw=0,\n",
    "        markersize=14,\n",
    "        label=\"Medium effect\",\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"red\",\n",
    "        markerfacecolor=\"red\",\n",
    "        lw=0,\n",
    "        markersize=14,\n",
    "        label=\"Large effect\",\n",
    "    ),\n",
    "    Line2D([0], [0], marker=\"*\", color=\"red\", lw=0, markersize=18, label=\"p > 0.05\"),\n",
    "]\n",
    "\n",
    "\n",
    "def get_compare_df(results_df, model_name, metric, effect_col):\n",
    "    # Filter the results for the specified model and metric\n",
    "    df = results_df[\n",
    "        (results_df[\"model\"] == model_name) & (results_df[\"metric\"] == metric)\n",
    "    ].copy()\n",
    "    df[\"sampling_method\"] = df[\"method_vs\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_effect_bar(ax, sub, effect_col, thresholds, invert_y=False, metric_type=None):\n",
    "    # Draw barplot for effect size\n",
    "    sns.barplot(\n",
    "        x=\"sampling_method\",\n",
    "        y=effect_col,\n",
    "        hue=\"dataset_level\",\n",
    "        data=sub,\n",
    "        order=sampling_methods,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        [sampling_labels[sampling_methods.index(m)] for m in sampling_methods],\n",
    "        fontsize=20,\n",
    "    )\n",
    "    # y-axis settings\n",
    "    if invert_y:\n",
    "        ax.invert_yaxis()\n",
    "    ax.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "    # Markers for effect size and significance\n",
    "    for i, method in enumerate(sampling_methods):\n",
    "        for j, level in enumerate(\n",
    "            sorted(sub[\"dataset_level\"].unique(), key=lambda x: int(x))\n",
    "        ):\n",
    "            row = sub[\n",
    "                (sub[\"sampling_method\"] == method) & (sub[\"dataset_level\"] == level)\n",
    "            ]\n",
    "            if not row.empty:\n",
    "                effect = abs(row[effect_col].values[0])\n",
    "                pval = row[\"mw_p\"].values[0]\n",
    "                # marker\n",
    "                if effect < thresholds[0]:\n",
    "                    # Only plot p-value star, skip effect size marker\n",
    "                    for bar in ax.patches:\n",
    "                        x_pos = bar.get_x() + bar.get_width() / 2.0\n",
    "                        if (abs(x_pos - i) < 0.4) and np.isclose(\n",
    "                            bar.get_height(), row[effect_col].values[0], atol=1e-4\n",
    "                        ):\n",
    "                            if pval > 0.05:\n",
    "                                y_base = 0.02 if not invert_y else -0.02\n",
    "                                ax.scatter(\n",
    "                                    bar.get_x() + bar.get_width() / 2.0,\n",
    "                                    y_base,\n",
    "                                    marker=\"*\",\n",
    "                                    color=\"red\",\n",
    "                                    s=180,\n",
    "                                    zorder=21,\n",
    "                                )\n",
    "                    continue  # Skip effect size marker\n",
    "                elif effect < thresholds[1]:\n",
    "                    marker_style = dict(\n",
    "                        marker=\"x\", color=\"blue\", s=120, linewidths=3\n",
    "                    )  # Small effect\n",
    "                elif effect < thresholds[2]:\n",
    "                    marker_style = dict(\n",
    "                        marker=\"o\",\n",
    "                        facecolors=\"none\",\n",
    "                        edgecolors=\"orange\",\n",
    "                        s=120,\n",
    "                        linewidths=3,\n",
    "                    )  # Medium effect\n",
    "                else:\n",
    "                    marker_style = dict(marker=\"o\", color=\"red\", s=120)  # Large effect\n",
    "                # Find the corresponding bar\n",
    "                for bar in ax.patches:\n",
    "                    x_pos = bar.get_x() + bar.get_width() / 2.0\n",
    "                    if (abs(x_pos - i) < 0.4) and np.isclose(\n",
    "                        bar.get_height(), row[effect_col].values[0], atol=1e-4\n",
    "                    ):\n",
    "                        if not invert_y:\n",
    "                            y_eff = bar.get_height() + 0.015\n",
    "                        else:\n",
    "                            y_eff = bar.get_height() - 0.015\n",
    "                        ax.scatter(\n",
    "                            bar.get_x() + bar.get_width() / 2.0,\n",
    "                            y_eff,\n",
    "                            **marker_style,\n",
    "                            zorder=20,\n",
    "                        )\n",
    "\n",
    "                        if pval > 0.05:\n",
    "                            if not invert_y:\n",
    "                                y_base = 0.02\n",
    "                            else:\n",
    "                                y_base = -0.02\n",
    "                            ax.scatter(\n",
    "                                bar.get_x() + bar.get_width() / 2.0,\n",
    "                                y_base,\n",
    "                                marker=\"*\",\n",
    "                                color=\"red\",\n",
    "                                s=180,\n",
    "                                zorder=21,\n",
    "                            )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(28, 22), sharex=True)\n",
    "# Rows 1-2: FSCS vs other sampling methods within the same model\n",
    "for row, (model, metric, effect_col, thresholds, effect_label) in enumerate(\n",
    "    [\n",
    "        (\"RF\", \"r2\", \"r_rb\", ur_thresholds, \"R2 $r_{rb}$\"),\n",
    "        (\"RF\", \"r2\", \"CD\", cd_thresholds, \"R2 $\\\\delta$\"),\n",
    "        (\"RF\", \"rmsle\", \"r_rb\", ur_thresholds, \"RMSLE $r_{rb}$\"),\n",
    "        (\"RF\", \"rmsle\", \"CD\", cd_thresholds, \"RMSLE $\\\\delta$\"),\n",
    "        (\"LGB\", \"r2\", \"r_rb\", ur_thresholds, \"R2 $r_{rb}$\"),\n",
    "        (\"LGB\", \"r2\", \"CD\", cd_thresholds, \"R2 $\\\\delta$\"),\n",
    "        (\"LGB\", \"rmsle\", \"r_rb\", ur_thresholds, \"RMSLE $r_{rb}$\"),\n",
    "        (\"LGB\", \"rmsle\", \"CD\", cd_thresholds, \"RMSLE $\\\\delta$\"),\n",
    "    ]\n",
    "):\n",
    "    r = row // 4\n",
    "    c = row % 4\n",
    "    df = get_compare_df(results_df, model, metric, effect_col)\n",
    "    plot_effect_bar(\n",
    "        axes[r, c],\n",
    "        df,\n",
    "        effect_col,\n",
    "        thresholds,\n",
    "        invert_y=(\"rmsle\" in metric),\n",
    "        metric_type=metric,\n",
    "    )\n",
    "    axes[r, c].set_title(f\"FSCS vs Other in {model}\\n{effect_label}\", fontsize=22)\n",
    "    axes[r, c].set_xticklabels([])\n",
    "    axes[r, c].set_xlabel(\"\")\n",
    "    if c in [0, 2]:\n",
    "        axes[r, c].set_ylabel(\"$r_{rb}$\")\n",
    "    else:\n",
    "        axes[r, c].set_ylabel(\"$\\\\delta$\")\n",
    "\n",
    "    axes[r, c].grid(True, which=\"major\", axis=\"y\", linestyle=\"-\", linewidth=0.6)\n",
    "    axes[r, c].grid(True, which=\"minor\", axis=\"y\", linestyle=\"--\", linewidth=0.25)\n",
    "    axes[r, c].yaxis.set_major_locator(plt.MultipleLocator(0.2))\n",
    "    axes[r, c].yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "\n",
    "# Row 3: RF+FSCS vs LGB+Other\n",
    "for i, (metric, effect_col, thresholds, effect_label) in enumerate(\n",
    "    [\n",
    "        (\"r2\", \"r_rb\", ur_thresholds, \"R2 $r_{rb}$\"),\n",
    "        (\"r2\", \"CD\", cd_thresholds, \"R2 $\\\\delta$\"),\n",
    "        (\"rmsle\", \"r_rb\", ur_thresholds, \"RMSLE $r_{rb}$\"),\n",
    "        (\"rmsle\", \"CD\", cd_thresholds, \"RMSLE $\\\\delta$\"),\n",
    "    ]\n",
    "):\n",
    "    df = get_compare_df(results_df, \"RF_FSCS_vs_LGB_other\", metric, effect_col)\n",
    "    plot_effect_bar(\n",
    "        axes[2, i],\n",
    "        df,\n",
    "        effect_col,\n",
    "        thresholds,\n",
    "        invert_y=(\"rmsle\" in metric),\n",
    "        metric_type=metric,\n",
    "    )\n",
    "    axes[2, i].set_title(f\"RF+FSCS vs LGB+Other\\n{effect_label}\", fontsize=22)\n",
    "    axes[2, i].set_xticklabels([])\n",
    "    axes[2, i].set_xlabel(\"\")\n",
    "    if i in [0, 2]:\n",
    "        axes[2, i].set_ylabel(\"$r_{rb}$\")\n",
    "    else:\n",
    "        axes[2, i].set_ylabel(\"$\\\\delta$\")\n",
    "\n",
    "    axes[2, i].grid(True, which=\"major\", axis=\"y\", linestyle=\"-\", linewidth=0.6)\n",
    "    axes[2, i].grid(True, which=\"minor\", axis=\"y\", linestyle=\"--\", linewidth=0.25)\n",
    "    axes[2, i].yaxis.set_major_locator(plt.MultipleLocator(0.2))\n",
    "    axes[2, i].yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "\n",
    "# Row 4: LGB+FSCS vs RF+Other\n",
    "for i, (metric, effect_col, thresholds, effect_label) in enumerate(\n",
    "    [\n",
    "        (\"r2\", \"r_rb\", ur_thresholds, \"R2 $r_{rb}$\"),\n",
    "        (\"r2\", \"CD\", cd_thresholds, \"R2 $\\\\delta$\"),\n",
    "        (\"rmsle\", \"r_rb\", ur_thresholds, \"RMSLE $r_{rb}$\"),\n",
    "        (\"rmsle\", \"CD\", cd_thresholds, \"RMSLE $\\\\delta$\"),\n",
    "    ]\n",
    "):\n",
    "    df = get_compare_df(results_df, \"LGB_FSCS_vs_RF_other\", metric, effect_col)\n",
    "    plot_effect_bar(\n",
    "        axes[3, i],\n",
    "        df,\n",
    "        effect_col,\n",
    "        thresholds,\n",
    "        invert_y=(\"rmsle\" in metric),\n",
    "        metric_type=metric,\n",
    "    )\n",
    "    axes[3, i].set_title(f\"LGB+FSCS vs RF+Other\\n{effect_label}\", fontsize=22)\n",
    "    axes[3, i].set_xlabel(\"Sampling Method\", fontsize=22)\n",
    "    if i in [0, 2]:\n",
    "        axes[3, i].set_ylabel(\"$r_{rb}$\")\n",
    "    else:\n",
    "        axes[3, i].set_ylabel(\"$\\\\delta$\")\n",
    "\n",
    "    axes[3, i].grid(True, which=\"major\", axis=\"y\", linestyle=\"-\", linewidth=0.6)\n",
    "    axes[3, i].grid(True, which=\"minor\", axis=\"y\", linestyle=\"--\", linewidth=0.25)\n",
    "    axes[3, i].yaxis.set_major_locator(plt.MultipleLocator(0.2))\n",
    "    axes[3, i].yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "\n",
    "# Legend handling\n",
    "# Only show two legends below the first subplot in the last row\n",
    "handles1, labels1 = axes[3, 0].get_legend_handles_labels()\n",
    "legend1 = axes[3, 0].legend(\n",
    "    handles=handles1,\n",
    "    labels=labels1,\n",
    "    title=\"Data Size\",\n",
    "    loc=\"lower left\",\n",
    "    prop={\"size\": 19},\n",
    "    title_fontsize=19,\n",
    "    framealpha=0.7,\n",
    ")\n",
    "axes[3, 0].add_artist(legend1)\n",
    "legend2 = axes[3, 1].legend(\n",
    "    handles=effect_legend,\n",
    "    loc=\"lower right\",\n",
    "    title=\"Effect size\",\n",
    "    prop={\"size\": 19},\n",
    "    title_fontsize=19,\n",
    "    framealpha=0.6,\n",
    ")\n",
    "axes[3, 1].add_artist(legend2)\n",
    "# Remove legends from other subplots\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        if not (r == 3 and c == 0) | (r == 3 and c == 1):\n",
    "            axes[r, c].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Ksat_effectsize_barplot_4x4.jpg\", dpi=800, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b16f90",
   "metadata": {},
   "source": [
    "The following are the forest cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86edf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results\n",
    "lgb_results_df = pd.read_csv(\"lgbresults_icluROCAUC.csv\")\n",
    "rf_results_df = pd.read_csv(\"rfresults_icluROCAUC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9851e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sampling method, dataset level, and set_id\n",
    "lgb_results_with_methods = lgb_results_df.copy()\n",
    "lgb_results_with_methods[\"sampling_method\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[0]\n",
    ")\n",
    "lgb_results_with_methods[\"dataset_level\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-3]\n",
    ")\n",
    "lgb_results_with_methods[\"set_id\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1]\n",
    ")\n",
    "lgb_results_with_methods[\"model\"] = \"LGB\"\n",
    "\n",
    "rf_results_with_methods = rf_results_df.copy()\n",
    "rf_results_with_methods[\"sampling_method\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[0]\n",
    ")\n",
    "rf_results_with_methods[\"dataset_level\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-3]\n",
    ")\n",
    "rf_results_with_methods[\"set_id\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1]\n",
    ")\n",
    "rf_results_with_methods[\"model\"] = \"RF\"\n",
    "\n",
    "# Merge results\n",
    "combined_results_with_methods = pd.concat(\n",
    "    [rf_results_with_methods, lgb_results_with_methods], ignore_index=True\n",
    ")\n",
    "combined_results_with_methods = combined_results_with_methods[\n",
    "    [\n",
    "        \"sampling_method\",\n",
    "        \"dataset_level\",\n",
    "        \"set_id\",\n",
    "        \"test_accuracy\",\n",
    "        \"test_f1\",\n",
    "        \"roc_auc\",\n",
    "        \"model\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c296884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significance and effect size analysis\n",
    "metrics = [\n",
    "    \"test_accuracy\",\n",
    "    \"test_f1\",\n",
    "    \"roc_auc\",\n",
    "]\n",
    "models = [\"RF\", \"LGB\"]\n",
    "sampling_methods = combined_results_with_methods[\"sampling_method\"].unique()\n",
    "sampling_methods = [m for m in sampling_methods if m != \"FSCS\"]\n",
    "dataset_levels = combined_results_with_methods[\"dataset_level\"].unique()\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FSCS vs other sampling methods within the same model\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        for dataset_level in dataset_levels:\n",
    "            for idx, method in enumerate(sampling_methods):\n",
    "                fscs = combined_results_with_methods[\n",
    "                    (combined_results_with_methods[\"sampling_method\"] == \"FSCS\")\n",
    "                    & (combined_results_with_methods[\"model\"] == model)\n",
    "                    & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "                ]\n",
    "                other = combined_results_with_methods[\n",
    "                    (combined_results_with_methods[\"sampling_method\"] == method)\n",
    "                    & (combined_results_with_methods[\"model\"] == model)\n",
    "                    & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "                ]\n",
    "                merged = pd.merge(\n",
    "                    fscs,\n",
    "                    other,\n",
    "                    on=[\"dataset_level\", \"set_id\"],\n",
    "                    suffixes=(\"_fscs\", \"_other\"),\n",
    "                )\n",
    "                if len(merged) == 0:\n",
    "                    continue\n",
    "                diff = merged[f\"{metric}_fscs\"] - merged[f\"{metric}_other\"]\n",
    "                # Mann-Whitney U test and effect size r\n",
    "                try:\n",
    "                    stat, p_u = mannwhitneyu(\n",
    "                        merged[f\"{metric}_other\"],\n",
    "                        merged[f\"{metric}_fscs\"],\n",
    "                        alternative=\"two-sided\",\n",
    "                    )\n",
    "                    n1, n2 = len(merged[f\"{metric}_fscs\"]), len(\n",
    "                        merged[f\"{metric}_other\"]\n",
    "                    )\n",
    "                    r_rb = 1 - 2 * stat / (n1 * n2) if n1 > 0 and n2 > 0 else np.nan\n",
    "                except Exception:\n",
    "                    stat = np.nan\n",
    "                    p_u = np.nan\n",
    "                    r_rb = np.nan\n",
    "                # Cliff's delta\n",
    "                try:\n",
    "                    from cliffs_delta import cliffs_delta\n",
    "\n",
    "                    cd, _ = cliffs_delta(\n",
    "                        merged[f\"{metric}_fscs\"], merged[f\"{metric}_other\"]\n",
    "                    )\n",
    "                except Exception:\n",
    "                    cd = np.nan\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"model\": model,\n",
    "                        \"metric\": metric,\n",
    "                        \"dataset_level\": dataset_level,\n",
    "                        \"method_vs\": method,\n",
    "                        \"mw_U\": stat,\n",
    "                        \"mw_p\": p_u,\n",
    "                        \"r_rb\": r_rb,\n",
    "                        \"CD\": cd,\n",
    "                    }\n",
    "                )\n",
    "# 2. RF+FSCS vs LGB+Other Sampling Methods\n",
    "for metric in metrics:\n",
    "    for dataset_level in dataset_levels:\n",
    "        for method in sampling_methods:\n",
    "            rf_fscs = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == \"FSCS\")\n",
    "                & (combined_results_with_methods[\"model\"] == \"RF\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            lgb_other = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == method)\n",
    "                & (combined_results_with_methods[\"model\"] == \"LGB\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            merged = pd.merge(\n",
    "                rf_fscs,\n",
    "                lgb_other,\n",
    "                on=[\"dataset_level\", \"set_id\"],\n",
    "                suffixes=(\"_rf_fscs\", \"_lgb_other\"),\n",
    "            )\n",
    "            if len(merged) == 0:\n",
    "                continue\n",
    "            diff = merged[f\"{metric}_rf_fscs\"] - merged[f\"{metric}_lgb_other\"]\n",
    "            try:\n",
    "                stat, p_u = mannwhitneyu(\n",
    "                    merged[f\"{metric}_lgb_other\"],\n",
    "                    merged[f\"{metric}_rf_fscs\"],\n",
    "                    alternative=\"two-sided\",\n",
    "                )\n",
    "                n1, n2 = len(merged[f\"{metric}_rf_fscs\"]), len(\n",
    "                    merged[f\"{metric}_lgb_other\"]\n",
    "                )\n",
    "                r_rb = 1 - ((2 * stat) / (n1 * n2)) if n1 > 0 and n2 > 0 else np.nan\n",
    "            except Exception:\n",
    "                stat = np.nan\n",
    "                p_u = np.nan\n",
    "                r_rb = np.nan\n",
    "            try:\n",
    "                from cliffs_delta import cliffs_delta\n",
    "\n",
    "                cd, _ = cliffs_delta(\n",
    "                    merged[f\"{metric}_rf_fscs\"], merged[f\"{metric}_lgb_other\"]\n",
    "                )\n",
    "            except Exception:\n",
    "                cd = np.nan\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model\": \"RF_FSCS_vs_LGB_other\",\n",
    "                    \"metric\": metric,\n",
    "                    \"dataset_level\": dataset_level,\n",
    "                    \"method_vs\": method,\n",
    "                    \"mw_U\": stat,\n",
    "                    \"mw_p\": p_u,\n",
    "                    \"r_rb\": r_rb,\n",
    "                    \"CD\": cd,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# 3. LGB+FSCS vs RF+Other Sampling Methods\n",
    "for metric in metrics:\n",
    "    for dataset_level in dataset_levels:\n",
    "        for method in sampling_methods:\n",
    "            lgb_fscs = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == \"FSCS\")\n",
    "                & (combined_results_with_methods[\"model\"] == \"LGB\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            rf_other = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == method)\n",
    "                & (combined_results_with_methods[\"model\"] == \"RF\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            merged = pd.merge(\n",
    "                lgb_fscs,\n",
    "                rf_other,\n",
    "                on=[\"dataset_level\", \"set_id\"],\n",
    "                suffixes=(\"_lgb_fscs\", \"_rf_other\"),\n",
    "            )\n",
    "            if len(merged) == 0:\n",
    "                continue\n",
    "            diff = merged[f\"{metric}_lgb_fscs\"] - merged[f\"{metric}_rf_other\"]\n",
    "            try:\n",
    "                stat, p_u = mannwhitneyu(\n",
    "                    merged[f\"{metric}_rf_other\"],\n",
    "                    merged[f\"{metric}_lgb_fscs\"],\n",
    "                    alternative=\"two-sided\",\n",
    "                )\n",
    "                n1, n2 = len(merged[f\"{metric}_lgb_fscs\"]), len(\n",
    "                    merged[f\"{metric}_rf_other\"]\n",
    "                )\n",
    "                r_rb = 1 - 2 * stat / (n1 * n2) if n1 > 0 and n2 > 0 else np.nan\n",
    "            except Exception:\n",
    "                stat = np.nan\n",
    "                p_u = np.nan\n",
    "                r_rb = np.nan\n",
    "            try:\n",
    "                from cliffs_delta import cliffs_delta\n",
    "\n",
    "                cd, _ = cliffs_delta(\n",
    "                    merged[f\"{metric}_lgb_fscs\"], merged[f\"{metric}_rf_other\"]\n",
    "                )\n",
    "            except Exception:\n",
    "                cd = np.nan\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model\": \"LGB_FSCS_vs_RF_other\",\n",
    "                    \"metric\": metric,\n",
    "                    \"dataset_level\": dataset_level,\n",
    "                    \"method_vs\": method,\n",
    "                    \"mw_U\": stat,\n",
    "                    \"mw_p\": p_u,\n",
    "                    \"r_rb\": r_rb,\n",
    "                    \"CD\": cd,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Summary table\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 22})\n",
    "\n",
    "ur_thresholds = [0.1, 0.3, 0.5]\n",
    "cd_thresholds = [0.147, 0.33, 0.474]\n",
    "sampling_methods = [\n",
    "    \"BalancedSampling\",\n",
    "    \"clhs\",\n",
    "    \"SRS\",\n",
    "]\n",
    "sampling_labels = [\n",
    "    \"Balanced\\nSampling\",\n",
    "    \"CLHS\",\n",
    "    \"SRS\",\n",
    "]\n",
    "\n",
    "effect_legend = [\n",
    "    Line2D(\n",
    "        [0], [0], marker=\"x\", color=\"blue\", lw=0, markersize=14, label=\"Small effect\"\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"orange\",\n",
    "        markerfacecolor=\"none\",\n",
    "        lw=0,\n",
    "        markersize=14,\n",
    "        label=\"Medium effect\",\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"red\",\n",
    "        markerfacecolor=\"red\",\n",
    "        lw=0,\n",
    "        markersize=14,\n",
    "        label=\"Large effect\",\n",
    "    ),\n",
    "    Line2D([0], [0], marker=\"*\", color=\"red\", lw=0, markersize=18, label=\"p > 0.05\"),\n",
    "]\n",
    "\n",
    "\n",
    "def get_compare_df(results_df, model_name, metric, effect_col):\n",
    "    df = results_df[\n",
    "        (results_df[\"model\"] == model_name) & (results_df[\"metric\"] == metric)\n",
    "    ].copy()\n",
    "    df[\"sampling_method\"] = df[\"method_vs\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_effect_bar(ax, sub, effect_col, thresholds, invert_y=False, metric_type=None):\n",
    "    # metric_type\n",
    "    sns.barplot(\n",
    "        x=\"sampling_method\",\n",
    "        y=effect_col,\n",
    "        hue=\"dataset_level\",\n",
    "        data=sub,\n",
    "        order=sampling_methods,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        [sampling_labels[sampling_methods.index(m)] for m in sampling_methods],\n",
    "        fontsize=20,\n",
    "    )\n",
    "    # legend is handled outside the main loop\n",
    "    # y-axis\n",
    "    if invert_y:\n",
    "        ax.invert_yaxis()\n",
    "    ax.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "    # markers\n",
    "    for i, method in enumerate(sampling_methods):\n",
    "        for j, level in enumerate(\n",
    "            sorted(sub[\"dataset_level\"].unique(), key=lambda x: int(x))\n",
    "        ):\n",
    "            row = sub[\n",
    "                (sub[\"sampling_method\"] == method) & (sub[\"dataset_level\"] == level)\n",
    "            ]\n",
    "            if not row.empty:\n",
    "                effect = abs(row[effect_col].values[0])\n",
    "                pval = row[\"mw_p\"].values[0]\n",
    "                # marker\n",
    "                if effect < thresholds[0]:\n",
    "                    # Only plot p-value star, not effect size marker\n",
    "                    for bar in ax.patches:\n",
    "                        x_pos = bar.get_x() + bar.get_width() / 2.0\n",
    "                        if (abs(x_pos - i) < 0.4) and np.isclose(\n",
    "                            bar.get_height(), row[effect_col].values[0], atol=1e-4\n",
    "                        ):\n",
    "                            if pval > 0.05:\n",
    "                                y_base = 0.02 if not invert_y else -0.02\n",
    "                                ax.scatter(\n",
    "                                    bar.get_x() + bar.get_width() / 2.0,\n",
    "                                    y_base,\n",
    "                                    marker=\"*\",\n",
    "                                    color=\"red\",\n",
    "                                    s=180,\n",
    "                                    zorder=21,\n",
    "                                )\n",
    "                    continue  # Skip effect size marker\n",
    "                elif effect < thresholds[1]:\n",
    "                    marker_style = dict(\n",
    "                        marker=\"x\", color=\"blue\", s=120, linewidths=3\n",
    "                    )  # Small effect\n",
    "                elif effect < thresholds[2]:\n",
    "                    marker_style = dict(\n",
    "                        marker=\"o\",\n",
    "                        facecolors=\"none\",\n",
    "                        edgecolors=\"orange\",\n",
    "                        s=120,\n",
    "                        linewidths=3,\n",
    "                    )  # Medium effect\n",
    "                else:\n",
    "                    marker_style = dict(marker=\"o\", color=\"red\", s=120)  # Large effect\n",
    "                # Find bar\n",
    "                for bar in ax.patches:\n",
    "                    x_pos = bar.get_x() + bar.get_width() / 2.0\n",
    "                    if (abs(x_pos - i) < 0.4) and np.isclose(\n",
    "                        bar.get_height(), row[effect_col].values[0], atol=1e-4\n",
    "                    ):\n",
    "                        if not invert_y:\n",
    "                            y_eff = bar.get_height() + 0.015\n",
    "                        else:\n",
    "                            y_eff = bar.get_height() - 0.015\n",
    "                        ax.scatter(\n",
    "                            bar.get_x() + bar.get_width() / 2.0,\n",
    "                            y_eff,\n",
    "                            **marker_style,\n",
    "                            zorder=20,\n",
    "                        )\n",
    "\n",
    "                        if pval > 0.05:\n",
    "                            if not invert_y:\n",
    "                                y_base = 0.02\n",
    "                            else:\n",
    "                                y_base = -0.02\n",
    "                            ax.scatter(\n",
    "                                bar.get_x() + bar.get_width() / 2.0,\n",
    "                                y_base,\n",
    "                                marker=\"*\",\n",
    "                                color=\"red\",\n",
    "                                s=180,\n",
    "                                zorder=21,\n",
    "                            )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4, 6, figsize=(28, 22), sharey=True, sharex=True)\n",
    "\n",
    "# Row 1-2: FSCS vs other sampling methods within the same model\n",
    "for row, (model, metric, effect_col, thresholds, effect_label) in enumerate(\n",
    "    [\n",
    "        (\"RF\", \"test_accuracy\", \"r_rb\", ur_thresholds, \"Accuracy $r_{rb}$\"),\n",
    "        (\"RF\", \"test_accuracy\", \"CD\", cd_thresholds, \"Accuracy $\\\\delta$\"),\n",
    "        (\"RF\", \"test_f1\", \"r_rb\", ur_thresholds, \"F1 Score $r_{rb}$\"),\n",
    "        (\"RF\", \"test_f1\", \"CD\", cd_thresholds, \"F1 Score $\\\\delta$\"),\n",
    "        (\"RF\", \"roc_auc\", \"r_rb\", ur_thresholds, \"ROC-AUC $r_{rb}$\"),\n",
    "        (\"RF\", \"roc_auc\", \"CD\", cd_thresholds, \"ROC-AUC $\\\\delta$\"),\n",
    "        (\"LGB\", \"test_accuracy\", \"r_rb\", ur_thresholds, \"Accuracy $r_{rb}$\"),\n",
    "        (\"LGB\", \"test_accuracy\", \"CD\", cd_thresholds, \"Accuracy $\\\\delta$\"),\n",
    "        (\"LGB\", \"test_f1\", \"r_rb\", ur_thresholds, \"F1 Score $r_{rb}$\"),\n",
    "        (\"LGB\", \"test_f1\", \"CD\", cd_thresholds, \"F1 Score $\\\\delta$\"),\n",
    "        (\"LGB\", \"roc_auc\", \"r_rb\", ur_thresholds, \"ROC-AUC $r_{rb}$\"),\n",
    "        (\"LGB\", \"roc_auc\", \"CD\", cd_thresholds, \"ROC-AUC $\\\\delta$\"),\n",
    "    ]\n",
    "):\n",
    "    r = row // 6\n",
    "    c = row % 6\n",
    "    df = get_compare_df(results_df, model, metric, effect_col)\n",
    "    plot_effect_bar(\n",
    "        axes[r, c],\n",
    "        df,\n",
    "        effect_col,\n",
    "        thresholds,\n",
    "        invert_y=(\"rmsle\" in metric),\n",
    "        metric_type=metric,\n",
    "    )\n",
    "    axes[r, c].set_title(f\"FSCS vs Other in {model}\\n{effect_label}\", fontsize=22)\n",
    "    axes[r, c].set_xticklabels([])\n",
    "    axes[r, c].set_xlabel(\"\")\n",
    "    if c in [0, 2, 4]:\n",
    "        axes[r, c].set_ylabel(\"$r_{rb}$\")\n",
    "    else:\n",
    "        axes[r, c].set_ylabel(\"$\\\\delta$\")\n",
    "\n",
    "    axes[r, c].grid(True, which=\"major\", axis=\"y\", linestyle=\"-\", linewidth=0.6)\n",
    "    axes[r, c].grid(True, which=\"minor\", axis=\"y\", linestyle=\"--\", linewidth=0.25)\n",
    "    axes[r, c].yaxis.set_major_locator(plt.MultipleLocator(0.2))\n",
    "    axes[r, c].yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "\n",
    "# Row 3: RF+FSCS vs LGB+Other\n",
    "for i, (metric, effect_col, thresholds, effect_label) in enumerate(\n",
    "    [\n",
    "        (\"test_accuracy\", \"r_rb\", ur_thresholds, \"Accuracy $r_{rb}$\"),\n",
    "        (\"test_accuracy\", \"CD\", cd_thresholds, \"Accuracy $\\\\delta$\"),\n",
    "        (\"test_f1\", \"r_rb\", ur_thresholds, \"F1 Score $r_{rb}$\"),\n",
    "        (\"test_f1\", \"CD\", cd_thresholds, \"F1 Score $\\\\delta$\"),\n",
    "        (\"roc_auc\", \"r_rb\", ur_thresholds, \"ROC-AUC $r_{rb}$\"),\n",
    "        (\"roc_auc\", \"CD\", cd_thresholds, \"ROC-AUC $\\\\delta$\"),\n",
    "    ]\n",
    "):\n",
    "    df = get_compare_df(results_df, \"RF_FSCS_vs_LGB_other\", metric, effect_col)\n",
    "    plot_effect_bar(\n",
    "        axes[2, i],\n",
    "        df,\n",
    "        effect_col,\n",
    "        thresholds,\n",
    "        invert_y=(\"rmsle\" in metric),\n",
    "        metric_type=metric,\n",
    "    )\n",
    "    axes[2, i].set_title(f\"RF+FSCS vs LGB+Other\\n{effect_label}\", fontsize=22)\n",
    "    axes[2, i].set_xticklabels([])\n",
    "    axes[2, i].set_xlabel(\"\")\n",
    "    if i in [0, 2, 4]:\n",
    "        axes[2, i].set_ylabel(\"$r_{rb}$\")\n",
    "    else:\n",
    "        axes[2, i].set_ylabel(\"$\\\\delta$\")\n",
    "\n",
    "    axes[2, i].grid(True, which=\"major\", axis=\"y\", linestyle=\"-\", linewidth=0.6)\n",
    "    axes[2, i].grid(True, which=\"minor\", axis=\"y\", linestyle=\"--\", linewidth=0.25)\n",
    "    axes[2, i].yaxis.set_major_locator(plt.MultipleLocator(0.2))\n",
    "    axes[2, i].yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "\n",
    "# Row 4: LGB+FSCS vs RF+Other\n",
    "for i, (metric, effect_col, thresholds, effect_label) in enumerate(\n",
    "    [\n",
    "        (\"test_accuracy\", \"r_rb\", ur_thresholds, \"Accuracy $r_{rb}$\"),\n",
    "        (\"test_accuracy\", \"CD\", cd_thresholds, \"Accuracy $\\\\delta$\"),\n",
    "        (\"test_f1\", \"r_rb\", ur_thresholds, \"F1 Score $r_{rb}$\"),\n",
    "        (\"test_f1\", \"CD\", cd_thresholds, \"F1 Score $\\\\delta$\"),\n",
    "        (\"roc_auc\", \"r_rb\", ur_thresholds, \"ROC-AUC $r_{rb}$\"),\n",
    "        (\"roc_auc\", \"CD\", cd_thresholds, \"ROC-AUC $\\\\delta$\"),\n",
    "    ]\n",
    "):\n",
    "    df = get_compare_df(results_df, \"LGB_FSCS_vs_RF_other\", metric, effect_col)\n",
    "    plot_effect_bar(\n",
    "        axes[3, i],\n",
    "        df,\n",
    "        effect_col,\n",
    "        thresholds,\n",
    "        invert_y=(\"rmsle\" in metric),\n",
    "        metric_type=metric,\n",
    "    )\n",
    "    axes[3, i].set_title(f\"LGB+FSCS vs RF+Other\\n{effect_label}\", fontsize=22)\n",
    "    axes[3, i].set_xlabel(\"Sampling Method\", fontsize=22)\n",
    "    if i in [0, 2, 4]:\n",
    "        axes[3, i].set_ylabel(\"$r_{rb}$\")\n",
    "    else:\n",
    "        axes[3, i].set_ylabel(\"$\\\\delta$\")\n",
    "\n",
    "    axes[3, i].grid(True, which=\"major\", axis=\"y\", linestyle=\"-\", linewidth=0.6)\n",
    "    axes[3, i].grid(True, which=\"minor\", axis=\"y\", linestyle=\"--\", linewidth=0.25)\n",
    "    axes[3, i].yaxis.set_major_locator(plt.MultipleLocator(0.2))\n",
    "    axes[3, i].yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "\n",
    "# legend handling\n",
    "# Only show two legends below the first subplot in the last row\n",
    "handles1, labels1 = axes[3, 0].get_legend_handles_labels()\n",
    "legend1 = axes[3, 0].legend(\n",
    "    handles=handles1,\n",
    "    labels=labels1,\n",
    "    title=\"Data Size\",\n",
    "    loc=\"center left\",\n",
    "    prop={\"size\": 19},\n",
    "    title_fontsize=19,\n",
    "    framealpha=0.7,\n",
    ")\n",
    "axes[3, 0].add_artist(legend1)\n",
    "legend2 = axes[3, 1].legend(\n",
    "    handles=effect_legend,\n",
    "    loc=\"center right\",\n",
    "    title=\"Effect size\",\n",
    "    prop={\"size\": 19},\n",
    "    title_fontsize=19,\n",
    "    framealpha=0.6,\n",
    ")\n",
    "axes[3, 1].add_artist(legend2)\n",
    "# Other subplots do not show legend\n",
    "for r in range(4):\n",
    "    for c in range(6):\n",
    "        if not (r == 3 and c == 0) | (r == 3 and c == 1):\n",
    "            axes[r, c].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"forest_effectsize_barplot_2x2.jpg\", dpi=800, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18eddb",
   "metadata": {},
   "source": [
    "The following compares LGB+balanced sampling/CLHS/FSCS/SRS vs. RF+SRS in Ksat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results\n",
    "lgb_results_df = pd.read_csv(\"lgbKsatresults_all.csv\")\n",
    "rf_results_df = pd.read_csv(\"rfKsatresults_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sampling method, dataset level, and set_id\n",
    "lgb_results_with_methods = lgb_results_df.copy()\n",
    "lgb_results_with_methods[\"sampling_method\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[0]\n",
    ")\n",
    "lgb_results_with_methods[\"dataset_level\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-3]\n",
    ")\n",
    "lgb_results_with_methods[\"set_id\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1]\n",
    ")\n",
    "lgb_results_with_methods[\"model\"] = \"LGB\"\n",
    "\n",
    "rf_results_with_methods = rf_results_df.copy()\n",
    "rf_results_with_methods[\"sampling_method\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[0]\n",
    ")\n",
    "rf_results_with_methods[\"dataset_level\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-3]\n",
    ")\n",
    "rf_results_with_methods[\"set_id\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1]\n",
    ")\n",
    "rf_results_with_methods[\"model\"] = \"RF\"\n",
    "\n",
    "# Merge results\n",
    "combined_results_with_methods = pd.concat(\n",
    "    [rf_results_with_methods, lgb_results_with_methods], ignore_index=True\n",
    ")\n",
    "combined_results_with_methods = combined_results_with_methods[\n",
    "    [\"sampling_method\", \"dataset_level\", \"set_id\", \"r2\", \"rmsle\", \"model\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55178fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significance and effect size analysis\n",
    "metrics = [\"r2\", \"rmsle\"]\n",
    "models = [\"RF\", \"LGB\"]\n",
    "sampling_methods = combined_results_with_methods[\"sampling_method\"].unique()\n",
    "sampling_methods = [m for m in sampling_methods if m != \"FSCS\"]\n",
    "dataset_levels = combined_results_with_methods[\"dataset_level\"].unique()\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ea5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LGB + BalancedSampling/CLHS/FSCS/SRS vs RF + SRS\n",
    "for method in [\"BalancedSampling\", \"clhs\", \"FSCS\", \"SRS\"]:\n",
    "    for metric in metrics:\n",
    "        for dataset_level in dataset_levels:\n",
    "            lgb_method = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == method)\n",
    "                & (combined_results_with_methods[\"model\"] == \"LGB\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            rf_srs = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == \"SRS\")\n",
    "                & (combined_results_with_methods[\"model\"] == \"RF\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            merged = pd.merge(\n",
    "                lgb_method,\n",
    "                rf_srs,\n",
    "                on=[\"dataset_level\", \"set_id\"],\n",
    "                suffixes=(\"_lgb\", \"_rf\"),\n",
    "            )\n",
    "            if len(merged) == 0:\n",
    "                continue\n",
    "            diff = merged[f\"{metric}_lgb\"] - merged[f\"{metric}_rf\"]\n",
    "            try:\n",
    "                stat, p_u = mannwhitneyu(\n",
    "                    merged[f\"{metric}_rf\"],\n",
    "                    merged[f\"{metric}_lgb\"],\n",
    "                    alternative=\"two-sided\",\n",
    "                )\n",
    "                n1, n2 = len(merged[f\"{metric}_rf\"]), len(merged[f\"{metric}_lgb\"])\n",
    "                r_rb = 1 - 2 * stat / (n1 * n2) if n1 > 0 and n2 > 0 else np.nan\n",
    "            except Exception:\n",
    "                stat = np.nan\n",
    "                p_w = np.nan\n",
    "                r_rb = np.nan\n",
    "            try:\n",
    "                cd, _ = cliffs_delta(merged[f\"{metric}_lgb\"], merged[f\"{metric}_rf\"])\n",
    "            except Exception:\n",
    "                cd = np.nan\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model\": \"LGB_method_vs_RF_SRS\",\n",
    "                    \"metric\": metric,\n",
    "                    \"dataset_level\": dataset_level,\n",
    "                    \"method_vs\": method,\n",
    "                    \"mw_U\": stat,\n",
    "                    \"mw_p\": p_u,\n",
    "                    \"r_rb\": r_rb,\n",
    "                    \"CD\": cd,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Summary table\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e05c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 22})\n",
    "\n",
    "# Thresholds for effect size\n",
    "ur_thresholds = [0.1, 0.3, 0.5]\n",
    "cd_thresholds = [0.147, 0.33, 0.474]\n",
    "sampling_methods = [\"BalancedSampling\", \"clhs\", \"FSCS\", \"SRS\"]\n",
    "sampling_labels = [\"Balanced\\nSampling\", \"CLHS\", \"FSCS\", \"SRS\"]\n",
    "\n",
    "# Legend for effect size markers\n",
    "effect_legend = [\n",
    "    Line2D(\n",
    "        [0], [0], marker=\"x\", color=\"blue\", lw=0, markersize=14, label=\"Small effect\"\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"orange\",\n",
    "        markerfacecolor=\"none\",\n",
    "        lw=0,\n",
    "        markersize=14,\n",
    "        label=\"Medium effect\",\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"red\",\n",
    "        markerfacecolor=\"red\",\n",
    "        lw=0,\n",
    "        markersize=14,\n",
    "        label=\"Large effect\",\n",
    "    ),\n",
    "    Line2D([0], [0], marker=\"*\", color=\"red\", lw=0, markersize=18, label=\"p > 0.05\"),\n",
    "]\n",
    "\n",
    "\n",
    "def get_compare_df(results_df, model_name, metric, effect_col):\n",
    "    # Filter the results for the specified model and metric\n",
    "    df = results_df[\n",
    "        (results_df[\"model\"] == model_name) & (results_df[\"metric\"] == metric)\n",
    "    ].copy()\n",
    "    df[\"sampling_method\"] = df[\"method_vs\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_effect_bar(ax, sub, effect_col, thresholds, invert_y=False, metric_type=None):\n",
    "    # Plot bar chart for effect size\n",
    "    if sub.empty:\n",
    "        ax.axis(\"off\")\n",
    "        return\n",
    "    sns.barplot(\n",
    "        x=\"sampling_method\",\n",
    "        y=effect_col,\n",
    "        hue=\"dataset_level\",\n",
    "        data=sub,\n",
    "        order=sampling_methods,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        [sampling_labels[sampling_methods.index(m)] for m in sampling_methods],\n",
    "        fontsize=18,\n",
    "    )\n",
    "    if invert_y:\n",
    "        ax.invert_yaxis()\n",
    "    ax.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "    # Add effect size and significance markers\n",
    "    for i, method in enumerate(sampling_methods):\n",
    "        for j, level in enumerate(\n",
    "            sorted(sub[\"dataset_level\"].unique(), key=lambda x: int(x))\n",
    "        ):\n",
    "            row = sub[\n",
    "                (sub[\"sampling_method\"] == method) & (sub[\"dataset_level\"] == level)\n",
    "            ]\n",
    "            if not row.empty:\n",
    "                effect = abs(row[effect_col].values[0])\n",
    "                pval = row[\"mw_p\"].values[0]\n",
    "                # marker\n",
    "                if effect < thresholds[0]:\n",
    "                    # Only plot p-value star, skip effect size marker\n",
    "                    for bar in ax.patches:\n",
    "                        x_pos = bar.get_x() + bar.get_width() / 2.0\n",
    "                        if (abs(x_pos - i) < 0.4) and np.isclose(\n",
    "                            bar.get_height(), row[effect_col].values[0], atol=1e-4\n",
    "                        ):\n",
    "                            if pval > 0.05:\n",
    "                                y_base = 0.02 if not invert_y else -0.02\n",
    "                                ax.scatter(\n",
    "                                    bar.get_x() + bar.get_width() / 2.0,\n",
    "                                    y_base,\n",
    "                                    marker=\"*\",\n",
    "                                    color=\"red\",\n",
    "                                    s=180,\n",
    "                                    zorder=21,\n",
    "                                )\n",
    "                    continue  # Skip effect size marker\n",
    "                elif effect < thresholds[1]:\n",
    "                    marker_style = dict(\n",
    "                        marker=\"x\", color=\"blue\", s=120, linewidths=3\n",
    "                    )  # Small effect\n",
    "                elif effect < thresholds[2]:\n",
    "                    marker_style = dict(\n",
    "                        marker=\"o\",\n",
    "                        facecolors=\"none\",\n",
    "                        edgecolors=\"orange\",\n",
    "                        s=120,\n",
    "                        linewidths=3,\n",
    "                    )  # Medium effect\n",
    "                else:\n",
    "                    marker_style = dict(marker=\"o\", color=\"red\", s=120)  # Large effect\n",
    "                for bar in ax.patches:\n",
    "                    x_pos = bar.get_x() + bar.get_width() / 2.0\n",
    "                    if (abs(x_pos - i) < 0.4) and np.isclose(\n",
    "                        bar.get_height(), row[effect_col].values[0], atol=1e-4\n",
    "                    ):\n",
    "                        y_eff = (\n",
    "                            bar.get_height() + 0.015\n",
    "                            if not invert_y\n",
    "                            else bar.get_height() - 0.015\n",
    "                        )\n",
    "                        ax.scatter(\n",
    "                            bar.get_x() + bar.get_width() / 2.0,\n",
    "                            y_eff,\n",
    "                            **marker_style,\n",
    "                            zorder=20,\n",
    "                        )\n",
    "                        if pval > 0.05:\n",
    "                            y_base = 0.02 if not invert_y else -0.02\n",
    "                            ax.scatter(\n",
    "                                bar.get_x() + bar.get_width() / 2.0,\n",
    "                                y_base,\n",
    "                                marker=\"*\",\n",
    "                                color=\"red\",\n",
    "                                s=180,\n",
    "                                zorder=21,\n",
    "                            )\n",
    "\n",
    "\n",
    "# Draw 2x2 subplots for effect size comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12), sharex=True)\n",
    "plot_settings = [\n",
    "    (\"r2\", \"r_rb\", ur_thresholds, \"R2 $r_{rb}$\"),\n",
    "    (\"r2\", \"CD\", cd_thresholds, \"R2 $\\\\delta$\"),\n",
    "    (\"rmsle\", \"r_rb\", ur_thresholds, \"RMSLE $r_{rb}$\"),\n",
    "    (\"rmsle\", \"CD\", cd_thresholds, \"RMSLE $\\\\delta$\"),\n",
    "]\n",
    "for idx, (metric, effect_col, thresholds, effect_label) in enumerate(plot_settings):\n",
    "    r, c = divmod(idx, 2)\n",
    "    df = get_compare_df(results_df, \"LGB_method_vs_RF_SRS\", metric, effect_col)\n",
    "    plot_effect_bar(\n",
    "        axes[r, c],\n",
    "        df,\n",
    "        effect_col,\n",
    "        thresholds,\n",
    "        invert_y=(\"rmsle\" in metric),\n",
    "        metric_type=metric,\n",
    "    )\n",
    "    axes[r, c].set_title(effect_label, fontsize=22)\n",
    "    axes[r, c].set_xlabel(\"Sampling Method\", fontsize=18)\n",
    "    if c == 0:\n",
    "        axes[r, c].set_ylabel(\"$r_{rb}$\")\n",
    "    else:\n",
    "        axes[r, c].set_ylabel(\"$\\\\delta$\")\n",
    "\n",
    "    axes[r, c].grid(True, which=\"major\", axis=\"y\", linestyle=\"-\", linewidth=0.6)\n",
    "    axes[r, c].grid(True, which=\"minor\", axis=\"y\", linestyle=\"--\", linewidth=0.25)\n",
    "    axes[r, c].yaxis.set_major_locator(plt.MultipleLocator(0.2))\n",
    "    axes[r, c].yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "\n",
    "# Add legends\n",
    "handles1, labels1 = axes[1, 0].get_legend_handles_labels()\n",
    "legend1 = axes[1, 0].legend(\n",
    "    handles=handles1,\n",
    "    labels=labels1,\n",
    "    title=\"Data Size\",\n",
    "    loc=\"center left\",\n",
    "    prop={\"size\": 16},\n",
    "    title_fontsize=16,\n",
    "    framealpha=0.7,\n",
    ")\n",
    "axes[1, 0].add_artist(legend1)\n",
    "legend2 = axes[1, 1].legend(\n",
    "    handles=effect_legend,\n",
    "    loc=\"center left\",\n",
    "    title=\"Effect size\",\n",
    "    prop={\"size\": 16},\n",
    "    title_fontsize=16,\n",
    "    framealpha=0.6,\n",
    "    bbox_to_anchor=(0, 0.54),  # (x, y) relative to the upper left of the subplot\n",
    ")\n",
    "axes[1, 1].add_artist(legend2)\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        if not (r == 1 and c in [0, 1]):\n",
    "            axes[r, c].get_legend().remove()\n",
    "\n",
    "plt.suptitle(\"LGB + Sampling Methods vs RF + SRS\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Ksat_LGBvsRF_SRS_effectsize_barplot_2x2.jpg\", dpi=800, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96584098",
   "metadata": {},
   "source": [
    "The following compares LGB+balanced sampling/CLHS/FSCS/SRS vs. RF+SRS in forest cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results\n",
    "lgb_results_df = pd.read_csv(\"lgbresults_icluROCAUC.csv\")\n",
    "rf_results_df = pd.read_csv(\"rfresults_icluROCAUC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28454f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sampling method, dataset level, and set_id\n",
    "lgb_results_with_methods = lgb_results_df.copy()\n",
    "lgb_results_with_methods[\"sampling_method\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[0]\n",
    ")\n",
    "lgb_results_with_methods[\"dataset_level\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-3]\n",
    ")\n",
    "lgb_results_with_methods[\"set_id\"] = lgb_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1]\n",
    ")\n",
    "lgb_results_with_methods[\"model\"] = \"LGB\"\n",
    "\n",
    "rf_results_with_methods = rf_results_df.copy()\n",
    "rf_results_with_methods[\"sampling_method\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[0]\n",
    ")\n",
    "rf_results_with_methods[\"dataset_level\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-3]\n",
    ")\n",
    "rf_results_with_methods[\"set_id\"] = rf_results_with_methods[\"dataset\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1]\n",
    ")\n",
    "rf_results_with_methods[\"model\"] = \"RF\"\n",
    "\n",
    "# Combine\n",
    "combined_results_with_methods = pd.concat(\n",
    "    [rf_results_with_methods, lgb_results_with_methods], ignore_index=True\n",
    ")\n",
    "combined_results_with_methods = combined_results_with_methods[\n",
    "    [\n",
    "        \"sampling_method\",\n",
    "        \"dataset_level\",\n",
    "        \"set_id\",\n",
    "        \"test_accuracy\",\n",
    "        \"test_f1\",\n",
    "        \"roc_auc\",\n",
    "        \"model\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significance and effect size analysis\n",
    "metrics = [\n",
    "    \"test_accuracy\",\n",
    "    \"test_f1\",\n",
    "    \"roc_auc\",\n",
    "]\n",
    "models = [\"RF\", \"LGB\"]\n",
    "sampling_methods = combined_results_with_methods[\"sampling_method\"].unique()\n",
    "sampling_methods = [m for m in sampling_methods if m != \"FSCS\"]\n",
    "dataset_levels = combined_results_with_methods[\"dataset_level\"].unique()\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LGB + BalancedSampling/CLHS/FSCS/SRS vs RF + SRS\n",
    "for method in [\"BalancedSampling\", \"clhs\", \"FSCS\", \"SRS\"]:\n",
    "    for metric in metrics:\n",
    "        for dataset_level in dataset_levels:\n",
    "            lgb_method = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == method)\n",
    "                & (combined_results_with_methods[\"model\"] == \"LGB\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            rf_srs = combined_results_with_methods[\n",
    "                (combined_results_with_methods[\"sampling_method\"] == \"SRS\")\n",
    "                & (combined_results_with_methods[\"model\"] == \"RF\")\n",
    "                & (combined_results_with_methods[\"dataset_level\"] == dataset_level)\n",
    "            ]\n",
    "            merged = pd.merge(\n",
    "                lgb_method,\n",
    "                rf_srs,\n",
    "                on=[\"dataset_level\", \"set_id\"],\n",
    "                suffixes=(\"_lgb\", \"_rf\"),\n",
    "            )\n",
    "            if len(merged) == 0:\n",
    "                continue\n",
    "            diff = merged[f\"{metric}_lgb\"] - merged[f\"{metric}_rf\"]\n",
    "            try:\n",
    "                stat, p_u = mannwhitneyu(\n",
    "                    merged[f\"{metric}_rf\"],\n",
    "                    merged[f\"{metric}_lgb\"],\n",
    "                    alternative=\"two-sided\",\n",
    "                )\n",
    "                n1, n2 = len(merged[f\"{metric}_rf\"]), len(merged[f\"{metric}_lgb\"])\n",
    "                r_rb = 1 - 2 * stat / (n1 * n2) if n1 > 0 and n2 > 0 else np.nan\n",
    "            except Exception:\n",
    "                stat = np.nan\n",
    "                p_w = np.nan\n",
    "                r_rb = np.nan\n",
    "            try:\n",
    "                cd, _ = cliffs_delta(merged[f\"{metric}_lgb\"], merged[f\"{metric}_rf\"])\n",
    "            except Exception:\n",
    "                cd = np.nan\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model\": \"LGB_method_vs_RF_SRS\",\n",
    "                    \"metric\": metric,\n",
    "                    \"dataset_level\": dataset_level,\n",
    "                    \"method_vs\": method,\n",
    "                    \"mw_U\": stat,\n",
    "                    \"mw_p\": p_u,\n",
    "                    \"r_rb\": r_rb,\n",
    "                    \"CD\": cd,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Summary table\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f730d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 22})\n",
    "\n",
    "# Thresholds for r_rb and Cliff's delta effect size\n",
    "ur_thresholds = [0.1, 0.3, 0.5]\n",
    "cd_thresholds = [0.147, 0.33, 0.474]\n",
    "sampling_methods = [\"BalancedSampling\", \"clhs\", \"FSCS\", \"SRS\"]\n",
    "sampling_labels = [\"Balanced\\nSampling\", \"CLHS\", \"FSCS\", \"SRS\"]\n",
    "\n",
    "# Effect size legend\n",
    "effect_legend = [\n",
    "    Line2D(\n",
    "        [0], [0], marker=\"x\", color=\"blue\", lw=0, markersize=14, label=\"Small effect\"\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"orange\",\n",
    "        markerfacecolor=\"none\",\n",
    "        lw=0,\n",
    "        markersize=14,\n",
    "        label=\"Medium effect\",\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"red\",\n",
    "        markerfacecolor=\"red\",\n",
    "        lw=0,\n",
    "        markersize=14,\n",
    "        label=\"Large effect\",\n",
    "    ),\n",
    "    Line2D([0], [0], marker=\"*\", color=\"red\", lw=0, markersize=18, label=\"p > 0.05\"),\n",
    "]\n",
    "\n",
    "\n",
    "def get_compare_df(results_df, model_name, metric, effect_col):\n",
    "    # Filter the results for the specified model and metric\n",
    "    df = results_df[\n",
    "        (results_df[\"model\"] == model_name) & (results_df[\"metric\"] == metric)\n",
    "    ].copy()\n",
    "    df[\"sampling_method\"] = df[\"method_vs\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_effect_bar(ax, sub, effect_col, thresholds, invert_y=False, metric_type=None):\n",
    "    # If the data is empty, hide the axis\n",
    "    if sub.empty:\n",
    "        ax.axis(\"off\")\n",
    "        return\n",
    "    # Draw barplot\n",
    "    sns.barplot(\n",
    "        x=\"sampling_method\",\n",
    "        y=effect_col,\n",
    "        hue=\"dataset_level\",\n",
    "        data=sub,\n",
    "        order=sampling_methods,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        [sampling_labels[sampling_methods.index(m)] for m in sampling_methods],\n",
    "        fontsize=18,\n",
    "    )\n",
    "    # Invert y-axis if needed\n",
    "    if invert_y:\n",
    "        ax.invert_yaxis()\n",
    "    ax.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "    # Mark effect size and significance\n",
    "    for i, method in enumerate(sampling_methods):\n",
    "        for j, level in enumerate(\n",
    "            sorted(sub[\"dataset_level\"].unique(), key=lambda x: int(x))\n",
    "        ):\n",
    "            row = sub[\n",
    "                (sub[\"sampling_method\"] == method) & (sub[\"dataset_level\"] == level)\n",
    "            ]\n",
    "            if not row.empty:\n",
    "                effect = abs(row[effect_col].values[0])\n",
    "                pval = row[\"mw_p\"].values[0]\n",
    "                # marker\n",
    "                if effect < thresholds[0]:\n",
    "                    # Only plot p-value star, skip effect size marker\n",
    "                    for bar in ax.patches:\n",
    "                        x_pos = bar.get_x() + bar.get_width() / 2.0\n",
    "                        if (abs(x_pos - i) < 0.4) and np.isclose(\n",
    "                            bar.get_height(), row[effect_col].values[0], atol=1e-4\n",
    "                        ):\n",
    "                            if pval > 0.05:\n",
    "                                y_base = 0.02 if not invert_y else -0.02\n",
    "                                ax.scatter(\n",
    "                                    bar.get_x() + bar.get_width() / 2.0,\n",
    "                                    y_base,\n",
    "                                    marker=\"*\",\n",
    "                                    color=\"red\",\n",
    "                                    s=180,\n",
    "                                    zorder=21,\n",
    "                                )\n",
    "                    continue  # Skip effect size marker\n",
    "                elif effect < thresholds[1]:\n",
    "                    marker_style = dict(\n",
    "                        marker=\"x\", color=\"blue\", s=120, linewidths=3\n",
    "                    )  # Small effect\n",
    "                elif effect < thresholds[2]:\n",
    "                    marker_style = dict(\n",
    "                        marker=\"o\",\n",
    "                        facecolors=\"none\",\n",
    "                        edgecolors=\"orange\",\n",
    "                        s=120,\n",
    "                        linewidths=3,\n",
    "                    )  # Medium effect\n",
    "                else:\n",
    "                    marker_style = dict(marker=\"o\", color=\"red\", s=120)  # Large effect\n",
    "                for bar in ax.patches:\n",
    "                    x_pos = bar.get_x() + bar.get_width() / 2.0\n",
    "                    if (abs(x_pos - i) < 0.4) and np.isclose(\n",
    "                        bar.get_height(), row[effect_col].values[0], atol=1e-4\n",
    "                    ):\n",
    "                        y_eff = (\n",
    "                            bar.get_height() + 0.015\n",
    "                            if not invert_y\n",
    "                            else bar.get_height() - 0.015\n",
    "                        )\n",
    "                        ax.scatter(\n",
    "                            bar.get_x() + bar.get_width() / 2.0,\n",
    "                            y_eff,\n",
    "                            **marker_style,\n",
    "                            zorder=20,\n",
    "                        )\n",
    "                        if pval > 0.05:\n",
    "                            y_base = 0.02 if not invert_y else -0.02\n",
    "                            ax.scatter(\n",
    "                                bar.get_x() + bar.get_width() / 2.0,\n",
    "                                y_base,\n",
    "                                marker=\"*\",\n",
    "                                color=\"red\",\n",
    "                                s=180,\n",
    "                                zorder=21,\n",
    "                            )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 18), sharex=True)\n",
    "# Plot settings for each subplot: (metric, effect_col, thresholds, effect_label)\n",
    "plot_settings = [\n",
    "    (\"test_accuracy\", \"r_rb\", ur_thresholds, \"Accuracy $r_{rb}$\"),\n",
    "    (\"test_accuracy\", \"CD\", cd_thresholds, \"Accuracy $\\\\delta$\"),\n",
    "    (\"test_f1\", \"r_rb\", ur_thresholds, \"F1 Score $r_{rb}$\"),\n",
    "    (\"test_f1\", \"CD\", cd_thresholds, \"F1 Score $\\\\delta$\"),\n",
    "    (\"roc_auc\", \"r_rb\", ur_thresholds, \"ROC-AUC $r_{rb}$\"),\n",
    "    (\"roc_auc\", \"CD\", cd_thresholds, \"ROC-AUC $\\\\delta$\"),\n",
    "]\n",
    "for idx, (metric, effect_col, thresholds, effect_label) in enumerate(plot_settings):\n",
    "    r, c = divmod(idx, 2)\n",
    "    df = get_compare_df(results_df, \"LGB_method_vs_RF_SRS\", metric, effect_col)\n",
    "    plot_effect_bar(\n",
    "        axes[r, c],\n",
    "        df,\n",
    "        effect_col,\n",
    "        thresholds,\n",
    "        invert_y=(\"rmsle\" in metric),\n",
    "        metric_type=metric,\n",
    "    )\n",
    "    axes[r, c].set_title(effect_label, fontsize=22)\n",
    "    axes[r, c].set_xlabel(\"Sampling Method\", fontsize=18)\n",
    "    if c == 0:\n",
    "        axes[r, c].set_ylabel(\"$r_{rb}$\")\n",
    "    else:\n",
    "        axes[r, c].set_ylabel(\"$\\\\delta$\")\n",
    "\n",
    "    axes[r, c].grid(True, which=\"major\", axis=\"y\", linestyle=\"-\", linewidth=0.6)\n",
    "    axes[r, c].grid(True, which=\"minor\", axis=\"y\", linestyle=\"--\", linewidth=0.25)\n",
    "    axes[r, c].yaxis.set_major_locator(plt.MultipleLocator(0.2))\n",
    "    axes[r, c].yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "\n",
    "# legend\n",
    "handles1, labels1 = axes[2, 0].get_legend_handles_labels()\n",
    "legend1 = axes[2, 0].legend(\n",
    "    handles=handles1,\n",
    "    labels=labels1,\n",
    "    title=\"Data Size\",\n",
    "    loc=\"upper left\",\n",
    "    prop={\"size\": 16},\n",
    "    title_fontsize=16,\n",
    "    framealpha=0.7,\n",
    "    bbox_to_anchor=(0, 0.93),  # (x, y) relative to the upper left of the subplot\n",
    ")\n",
    "axes[2, 0].add_artist(legend1)\n",
    "legend2 = axes[2, 1].legend(\n",
    "    handles=effect_legend,\n",
    "    loc=\"upper left\",\n",
    "    title=\"Effect size\",\n",
    "    prop={\"size\": 16},\n",
    "    title_fontsize=16,\n",
    "    framealpha=0.6,\n",
    "    bbox_to_anchor=(0, 0.93),  # (x, y) relative to the upper left of the subplot\n",
    ")\n",
    "axes[2, 1].add_artist(legend2)\n",
    "for r in range(3):\n",
    "    for c in range(2):\n",
    "        if not (r == 3 and c in [0, 1]):\n",
    "            axes[r, c].get_legend().remove()\n",
    "\n",
    "plt.suptitle(\"LGB + Sampling Methods vs RF + SRS\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"forest_LGBvsRF_SRS_effectsize_barplot_3x2.jpg\", dpi=800, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
